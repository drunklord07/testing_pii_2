#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import sys
import traceback
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed
from collections import Counter
from datetime import datetime
from tqdm import tqdm

# ========== CONFIGURATION ==========
INPUT_FOLDER = "input_logs"          # <-- Hardcode your folder here
OUTPUT_FOLDER = "output_users"       # Combined extracted matches
NEW_ORIGINAL_FOLDER = "new_original" # Mirror of input minus extracted lines
SUMMARY_FILE = "summary_users.txt"
CHUNK_SIZE = 10000
MAX_WORKERS = 6
ALLOWED_EXTS = (".txt",)

# Regex to match users=[<10â€“12 digits>] with optional spaces/commas
USERS_REGEX = re.compile(r"users\s*=\s*\[\s*(\d{10,12})\s*\]\s*,?", re.IGNORECASE)
# ===================================

def find_txt_files(root: Path):
    return sorted([p for p in root.rglob("*") if p.suffix in ALLOWED_EXTS])

def extract_users_line(line: str):
    """
    Input line format (split from RIGHT):
      log line ; path ; UNIDENTIFIED_FIELD ; mobile_regex ; mobile match
    """
    parts = [p.strip() for p in line.rsplit(";", 4)]
    if len(parts) != 5:
        return None, False  # malformed

    logline, path_in_line, _unidentified, _regex_type, _mobile_match = parts
    m = USERS_REGEX.search(logline)
    if not m:
        return None, False

    number = m.group(1)
    extracted_log = f"users=[{number}]"
    formatted = f"{extracted_log} ; {path_in_line} ; users ; MOBILE_REGEX ; {number}"
    return (formatted, number), True

def process_file(file_path: Path, input_root: Path):
    stats = {
        "lines_scanned": 0,
        "lines_written": 0,
        "numbers": Counter(),
        "error": None,
        "blank": False
    }
    extracted = []
    cleaned_lines = []
    try:
        with file_path.open("r", encoding="utf-8", errors="ignore") as f:
            for raw in f:
                line = raw.rstrip("\n")
                stats["lines_scanned"] += 1
                res, matched = extract_users_line(line)
                if matched:
                    formatted, number = res
                    extracted.append(formatted)
                    stats["lines_written"] += 1
                    stats["numbers"][number] += 1
                else:
                    cleaned_lines.append(line)
        if stats["lines_scanned"] == 0:
            stats["blank"] = True
    except Exception as e:
        stats["error"] = f"{file_path}: {e}"

    # Write cleaned file into new_original/
    rel_path = file_path.relative_to(input_root)
    new_path = Path(NEW_ORIGINAL_FOLDER) / rel_path
    new_path.parent.mkdir(parents=True, exist_ok=True)
    with new_path.open("w", encoding="utf-8") as out_clean:
        for l in cleaned_lines:
            out_clean.write(l + "\n")

    return file_path, extracted, stats

def write_combined_chunks(all_outputs, out_dir):
    out_dir.mkdir(parents=True, exist_ok=True)
    chunk_idx = 1
    line_count = 0
    writer = None

    for line in all_outputs:
        if writer is None or line_count >= CHUNK_SIZE:
            if writer:
                writer.close()
            chunk_file = out_dir / f"combined_chunk{chunk_idx:04d}.txt"
            writer = chunk_file.open("w", encoding="utf-8")
            chunk_idx += 1
            line_count = 0
        writer.write(line + "\n")
        line_count += 1
    if writer:
        writer.close()

def write_summary(summary, numbers_counter):
    with open(SUMMARY_FILE, "w", encoding="utf-8") as f:
        f.write(f"Summary Report - users extractor\n")
        f.write(f"Generated: {datetime.now()}\n\n")
        f.write(f"Input folder       : {summary['input']}\n")
        f.write(f"Output folder      : {OUTPUT_FOLDER}\n")
        f.write(f"New original folder: {NEW_ORIGINAL_FOLDER}\n")
        f.write(f"Files scanned      : {summary['files_scanned']}\n")
        f.write(f"Total lines scanned: {summary['lines_scanned']}\n")
        f.write(f"Total numbers found: {summary['total_found']}\n")
        f.write(f"Total lines written: {summary['lines_written']}\n")
        f.write(f"Lines skipped (no match): {summary['lines_skipped']}\n")
        f.write(f"Blank files        : {summary['blank_files']}\n")
        f.write(f"Errors             : {len(summary['errors'])}\n")
        if summary['errors']:
            f.write("Error details:\n")
            for e in summary['errors']:
                f.write(f"  - {e}\n")
        f.write("\nPer-number frequency:\n")
        for num, count in numbers_counter.most_common():
            f.write(f"  {num} : {count}\n")

def main():
    input_folder = Path(INPUT_FOLDER)
    if not input_folder.exists():
        print(f"Input folder not found: {input_folder}")
        sys.exit(1)

    txt_files = find_txt_files(input_folder)
    summary = {
        "input": str(input_folder),
        "files_scanned": 0,
        "lines_scanned": 0,
        "total_found": 0,
        "lines_written": 0,
        "lines_skipped": 0,
        "blank_files": 0,
        "errors": []
    }
    numbers_counter = Counter()
    all_extracted = []

    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as ex:
        futures = {ex.submit(process_file, f, input_folder): f for f in txt_files}
        for fut in tqdm(as_completed(futures), total=len(futures), desc="Processing files"):
            fpath, outputs, stats = fut.result()
            summary["files_scanned"] += 1
            summary["lines_scanned"] += stats["lines_scanned"]
            summary["lines_written"] += stats["lines_written"]
            summary["total_found"] += sum(stats["numbers"].values())
            summary["lines_skipped"] += stats["lines_scanned"] - stats["lines_written"]
            if stats["blank"]:
                summary["blank_files"] += 1
            if stats["error"]:
                summary["errors"].append(stats["error"])
            numbers_counter.update(stats["numbers"])
            all_extracted.extend(outputs)

    # Write combined extracted results
    if all_extracted:
        write_combined_chunks(all_extracted, Path(OUTPUT_FOLDER))

    write_summary(summary, numbers_counter)
    print(f"\nDone. Extracted lines in {OUTPUT_FOLDER}, cleaned files in {NEW_ORIGINAL_FOLDER}, summary in {SUMMARY_FILE}")

if __name__ == "__main__":
    main()
