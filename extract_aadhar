#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Aadhaar-based line cleaner
--------------------------
Rules:
- For each line in each *.txt file under INPUT_FOLDER (recursive):
  * Extract 12-digit candidates not embedded in longer numbers.
  * If ANY candidate fails Aadhaar Verhoeff checksum => DROP the entire line.
  * Else (no candidates OR all candidates valid) => KEEP the line.
- Write kept lines into OUTPUT_FOLDER as chunked files of CHUNK_LINES lines each:
  chunk0001.txt, chunk0002.txt, ...
- Produce a summary_report.txt in OUTPUT_FOLDER.

Configuration is at the top. No temp files. Parallel file reads (threads).
"""

import os
import re
import sys
import traceback
from pathlib import Path
from typing import Dict, List, Tuple
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ========== CONFIGURE ONLY THESE ==========
INPUT_FOLDER   = "input_logs"          # <-- your input folder path
OUTPUT_FOLDER  = "aadhaar_cleaned"     # <-- output folder (created if missing)
CHUNK_LINES    = 10000                 # <-- lines per output file
MAX_WORKERS    = 6                     # <-- parallel readers (I/O bound)
REPORT_NAME    = "summary_report.txt"  # <-- name of summary file
# ==========================================


# ---------- Aadhaar Verhoeff ----------
@lru_cache(maxsize=10000)
def is_valid_aadhaar(number: str) -> bool:
    if len(number) != 12 or not number.isdigit():
        return False
    mul = [
        [0,1,2,3,4,5,6,7,8,9],
        [1,2,3,4,0,6,7,8,9,5],
        [2,3,4,0,1,7,8,9,5,6],
        [3,4,0,1,2,8,9,5,6,7],
        [4,0,1,2,3,9,5,6,7,8],
        [5,9,8,7,6,0,4,3,2,1],
        [6,5,9,8,7,1,0,4,3,2],
        [7,6,5,9,8,2,1,0,4,3],
        [8,7,6,5,9,3,2,1,0,4],
        [9,8,7,6,5,4,3,2,1,0]
    ]
    perm = [
        [0,1,2,3,4,5,6,7,8,9],
        [1,5,7,6,2,8,3,0,9,4],
        [5,8,0,3,7,9,6,1,4,2],
        [8,9,1,6,0,4,3,5,2,7],
        [9,4,5,3,1,2,6,8,7,0],
        [4,2,8,6,5,7,3,9,0,1],
        [2,7,9,3,8,0,6,4,1,5],
        [7,0,4,6,9,1,3,2,5,8]
    ]
    inv = [0,4,3,2,1,5,6,7,8,9]
    c = 0
    for i, ch in enumerate(reversed(number)):
        c = mul[c][perm[i % 8][int(ch)]]
    return inv[c] == 0


# ---------- Core logic ----------
AADHAAR_RE = re.compile(r'(?<!\d)\d{12}(?!\d)')  # exact 12 digits, not embedded


def should_keep_line(line: str) -> Tuple[bool, int, int]:
    """
    Returns (keep_line, valid_count, invalid_count) for the line.
    Rule: if any invalid Aadhaar found -> drop line (keep_line=False)
          else keep (True). If no candidates, keep.
    """
    candidates = AADHAAR_RE.findall(line)
    if not candidates:
        return True, 0, 0

    valid, invalid = 0, 0
    for num in candidates:
        if is_valid_aadhaar(num):
            valid += 1
        else:
            invalid += 1

    if invalid > 0:
        return False, valid, invalid
    return True, valid, 0


def process_one_file(path: Path) -> Dict:
    """
    Read one file, decide for each line whether to keep or drop.
    Return a dict with:
      {
        "file": str(path),
        "kept_lines": [str, ...],
        "lines_total": int,
        "lines_kept": int,
        "lines_dropped": int,
        "candidates": int,
        "valid": int,
        "invalid": int,
        "error": None|str
      }
    """
    stats = {
        "file": str(path),
        "kept_lines": [],
        "lines_total": 0,
        "lines_kept": 0,
        "lines_dropped": 0,
        "candidates": 0,
        "valid": 0,
        "invalid": 0,
        "error": None
    }

    try:
        with path.open("r", encoding="utf-8", errors="ignore") as f:
            for line in f:
                stats["lines_total"] += 1
                keep, v, inv = should_keep_line(line)
                stats["valid"] += v
                stats["invalid"] += inv
                stats["candidates"] += (v + inv)

                if keep:
                    stats["lines_kept"] += 1
                    stats["kept_lines"].append(line)
                else:
                    stats["lines_dropped"] += 1

    except Exception as e:
        stats["error"] = f"{type(e).__name__}: {e}"
        # On error, we don't keep any lines from this file.
        stats["kept_lines"] = []

    return stats


def find_txt_files(root: Path) -> List[Path]:
    return sorted(root.rglob("*.txt"))


# ---------- Chunk writer ----------
class ChunkWriter:
    def __init__(self, out_dir: Path, chunk_size: int):
        self.out_dir = out_dir
        self.chunk_size = chunk_size
        self.current_count = 0
        self.chunk_index = 1
        self.current_fp = None
        self.out_files = 0

        self.out_dir.mkdir(parents=True, exist_ok=True)

    def _open_new(self):
        if self.current_fp:
            self.current_fp.close()
        name = f"chunk{self.chunk_index:04d}.txt"
        self.current_fp = (self.out_dir / name).open("w", encoding="utf-8")
        self.chunk_index += 1
        self.current_count = 0
        self.out_files += 1

    def write_lines(self, lines: List[str]):
        i = 0
        while i < len(lines):
            if self.current_fp is None or self.current_count >= self.chunk_size:
                self._open_new()
            can_write = min(self.chunk_size - self.current_count, len(lines) - i)
            # Write a slice
            slice_ = lines[i:i + can_write]
            self.current_fp.writelines(slice_)
            self.current_count += can_write
            i += can_write

    def close(self):
        if self.current_fp:
            self.current_fp.close()
            self.current_fp = None


# ---------- Main ----------
def main():
    in_path = Path(INPUT_FOLDER)
    out_path = Path(OUTPUT_FOLDER)
    report_path = out_path / REPORT_NAME

    if not in_path.exists() or not in_path.is_dir():
        print(f"❌ INPUT_FOLDER not found or not a directory: {in_path}")
        sys.exit(1)

    out_path.mkdir(parents=True, exist_ok=True)

    files = find_txt_files(in_path)

    # Global counters
    g_files = 0
    g_errors = 0
    g_lines_total = 0
    g_lines_kept = 0
    g_lines_dropped = 0
    g_candidates = 0
    g_valid = 0
    g_invalid = 0

    per_file_rows: List[str] = []
    writer = ChunkWriter(out_path, CHUNK_LINES)

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        futures = [ex.submit(process_one_file, p) for p in files]

        for fut in tqdm(as_completed(futures), total=len(futures), desc="Cleaning files", unit="file"):
            res = fut.result()
            g_files += 1
            g_lines_total += res["lines_total"]
            g_lines_kept += res["lines_kept"]
            g_lines_dropped += res["lines_dropped"]
            g_candidates += res["candidates"]
            g_valid += res["valid"]
            g_invalid += res["invalid"]

            if res["error"]:
                g_errors += 1
                per_file_rows.append(f'{res["file"]} -> ERROR: {res["error"]}')
            else:
                per_file_rows.append(
                    f'{res["file"]} -> lines_total={res["lines_total"]}, kept={res["lines_kept"]}, '
                    f'dropped_invalid={res["lines_dropped"]}, candidates={res["candidates"]}, '
                    f'valid={res["valid"]}, invalid={res["invalid"]}'
                )
                # Write kept lines immediately to chunks, then free memory
                if res["kept_lines"]:
                    writer.write_lines(res["kept_lines"])

    writer.close()

    # Write summary
    try:
        with report_path.open("w", encoding="utf-8") as rf:
            rf.write("===== Aadhaar Cleaning Summary =====\n\n")
            rf.write(f"Input folder          : {in_path}\n")
            rf.write(f"Output folder         : {out_path}\n")
            rf.write(f"Output chunk size     : {CHUNK_LINES}\n")
            rf.write(f"Output files written  : {writer.out_files}\n\n")

            rf.write(f"Files scanned         : {g_files}\n")
            rf.write(f"Files with errors     : {g_errors}\n\n")

            rf.write(f"Total lines scanned   : {g_lines_total}\n")
            rf.write(f"Lines kept            : {g_lines_kept}\n")
            rf.write(f"Lines dropped (invalid Aadhaar present) : {g_lines_dropped}\n\n")

            rf.write(f"Total candidates (12-digit) : {g_candidates}\n")
            rf.write(f"Valid Aadhaar               : {g_valid}\n")
            rf.write(f"Invalid Aadhaar             : {g_invalid}\n\n")

            rf.write("----- Per-file breakdown -----\n")
            for row in per_file_rows:
                rf.write(row + "\n")
    except Exception as e:
        print(f"⚠️ Failed to write summary: {e}", file=sys.stderr)

    print(f"✅ Done. Summary: {report_path}")


if __name__ == "__main__":
    main()
